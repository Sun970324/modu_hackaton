{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langchain-community\n",
    "# !pip install openai\n",
    "# !pip install unstructured\n",
    "# !pip install \"unstructured[docx]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup  # HTML 태그 제거용 라이브러리\n",
    "import re  # 특수 문자 제거용 모듈\n",
    "\n",
    "class McDonaldsMenu:\n",
    "    def __init__(self):\n",
    "        # 메뉴 데이터를 가져올 API의 URL과 헤더 설정\n",
    "        self.url = \"https://www.mcdonalds.co.kr/kor/menu/listContent.do\"\n",
    "        self.detail_url = \"https://www.mcdonalds.co.kr/kor/menu/detail.do\"\n",
    "        self.headers = {\n",
    "            \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "            \"User-Agent\": \"Mozilla/5.0\"\n",
    "        }\n",
    "\n",
    "    # 특정 카테고리의 메뉴 데이터를 가져오는 메서드\n",
    "    def fetch_menu_data(self, sub_category_seq, page_num):\n",
    "        data = {\n",
    "            \"page\": page_num,\n",
    "            \"sub_category_seq\": sub_category_seq  # 서브 카테고리 번호를 포함한 데이터\n",
    "        }\n",
    "        try:\n",
    "            # POST 요청을 통해 메뉴 데이터를 가져옴\n",
    "            response = requests.post(self.url, headers=self.headers, data=data)\n",
    "            response.raise_for_status()\n",
    "            return response.json().get('list', [])  # 응답 데이터에서 'list' 항목을 반환\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"API 요청 실패: {e}\")  # 요청 실패 시 예외 처리\n",
    "            return []\n",
    "\n",
    "    # 메뉴의 상세 정보를 가져오는 메서드\n",
    "    def fetch_menu_detail(self, menu_code, sub_category_seq):\n",
    "        data = {\"seq\": menu_code, \"page\": 1, \"sub_category_seq\": sub_category_seq}  # 메뉴 코드와 서브 카테고리 정보\n",
    "        try:\n",
    "            # POST 요청을 통해 상세 메뉴 정보를 가져옴\n",
    "            response = requests.post(self.detail_url, headers=self.headers, data=data)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            # 메뉴 이름과 설명을 HTML에서 추출\n",
    "            menu_name_tag = soup.find('h2', class_='ko')\n",
    "            menu_desc_tag = soup.find('div', class_='desc')\n",
    "\n",
    "            # 메뉴 이름과 설명이 없을 경우 기본 메시지 설정\n",
    "            menu_name = menu_name_tag.get_text(strip=True) if menu_name_tag else \"메뉴 이름을 찾을 수 없음\"\n",
    "            menu_name = re.sub(r'[™®]', '', menu_name)  # 특수 기호 제거\n",
    "            \n",
    "            menu_desc = menu_desc_tag.get_text(strip=True) if menu_desc_tag else \"메뉴 설명을 찾을 수 없음\"\n",
    "            menu_desc = re.sub(r'[™®]', '', menu_desc)  # 특수 기호 및 판매 시간 관련 문구 제거\n",
    "            menu_desc = re.sub(r'\\*?판매\\s*시간\\s*[:：]?\\s*[^\\*]+', '', menu_desc).strip()\n",
    "\n",
    "            return {\"menu_name\": menu_name, \"menu_desc\": menu_desc}\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"상세 정보 API 요청 실패: {e}\")\n",
    "            return {}\n",
    "\n",
    "    # 메뉴의 영양 정보를 가져오는 메서드\n",
    "    def fetch_nutrition_data(self, seq, sub_category_seq):\n",
    "        data = {\"seq\": seq, \"page\": 1, \"sub_category_seq\": sub_category_seq}\n",
    "        try:\n",
    "            response = requests.post(self.detail_url, headers=self.headers, data=data)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            table = soup.find('table', class_='tableType01 nutrDesc')  # 영양 정보 테이블 찾기\n",
    "\n",
    "            if table:\n",
    "                # 테이블에서 데이터를 행 단위로 추출하여 리스트에 저장\n",
    "                rows = table.find_all('tr')\n",
    "                nutrition_info = [[col.text.strip() for col in row.find_all(['th', 'td'])] for row in rows]\n",
    "                return nutrition_info\n",
    "            else:\n",
    "                return []\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"영양 정보 API 요청 실패: {e}\")\n",
    "            return []\n",
    "\n",
    "    # 메뉴의 알러지 정보를 가져오는 메서드\n",
    "    def fetch_allergy_data(self, seq, sub_category_seq):\n",
    "        data = {\"seq\": seq, \"page\": 1, \"sub_category_seq\": sub_category_seq}\n",
    "        try:\n",
    "            response = requests.post(self.detail_url, headers=self.headers, data=data)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            allergy_info_section = soup.find('div', class_='allerDesc')\n",
    "            if allergy_info_section:\n",
    "                # 알러지 정보에서 특수 기호 제거 후 반환\n",
    "                allergy_info = allergy_info_section.get_text(strip=True)\n",
    "                return re.sub(r'[™®]', '', allergy_info)\n",
    "            else:\n",
    "                return \"알러지 정보 없음\"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return \"알러지 정보 요청 실패\"\n",
    "\n",
    "    # 메뉴의 원산지 정보를 가져오는 메서드\n",
    "    def fetch_origin_data(self, seq, sub_category_seq):\n",
    "        data = {\"seq\": seq, \"page\": 1, \"sub_category_seq\": sub_category_seq}\n",
    "        try:\n",
    "            response = requests.post(self.detail_url, headers=self.headers, data=data)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            origin_info_section = soup.find('ul', class_='origin_info')\n",
    "            if origin_info_section:\n",
    "                # 원산지 정보에서 특수 기호 제거 후 반환\n",
    "                origin_info = origin_info_section.get_text(strip=True)\n",
    "                return re.sub(r'[™®]', '', origin_info)\n",
    "            else:\n",
    "                return \"원산지 정보 없음\"\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            return \"원산지 정보 요청 실패\"\n",
    "\n",
    "    # 텍스트에서 특수 문자를 제거하는 메서드\n",
    "    def clean_text(self, text):\n",
    "        cleaned_text = BeautifulSoup(text, \"html.parser\").get_text()  # HTML 태그 제거\n",
    "        cleaned_text = re.sub(r'[™®]', '', cleaned_text)  # 특수 기호 제거\n",
    "        return cleaned_text\n",
    "\n",
    "    # 영양 정보를 포맷팅하는 메서드\n",
    "    def format_nutrition_info(self, nutrition_data):\n",
    "        if not nutrition_data:\n",
    "            return \"영양소 정보 없음\"\n",
    "        headers = nutrition_data[0]\n",
    "        values = nutrition_data[1]\n",
    "        formatted_nutrition = '\\n'.join([f\"{header}: {value}\" for header, value in zip(headers, values) if header != \"영양소\"])\n",
    "        return formatted_nutrition\n",
    "\n",
    "    # 모든 메뉴 데이터를 하나의 파일로 저장하는 메서드\n",
    "    def save_menus_to_file(self, all_menu_items_by_category):\n",
    "        with open(\"/content/drive/MyDrive/Aiffel/Project/all_menu_data.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "            for sub_category_seq, all_menu_items in all_menu_items_by_category.items():\n",
    "                for item in all_menu_items:\n",
    "                    kor_name = self.clean_text(item.get('kor_name', ''))\n",
    "                    menu_code = item.get('seq', '')\n",
    "                    menu_details = self.fetch_menu_detail(menu_code, sub_category_seq)\n",
    "                    f.write(f\"{kor_name}\\n제품소개 : {menu_details['menu_desc']}\\n\")\n",
    "                    nutrition_data = self.fetch_nutrition_data(menu_code, sub_category_seq)\n",
    "                    formatted_nutrition = self.format_nutrition_info(nutrition_data)\n",
    "                    f.write(f\"영양소 정보:\\n{formatted_nutrition}\\n\")\n",
    "                    allergy_info = self.fetch_allergy_data(menu_code, sub_category_seq)\n",
    "                    f.write(f\"알러지 정보: {allergy_info}\\n\")\n",
    "                    origin_info = self.fetch_origin_data(menu_code, sub_category_seq)\n",
    "                    f.write(f\"원산지 정보: {origin_info}\\n\\n\")\n",
    "        print(\"메뉴 데이터를 파일에 저장했습니다.\")\n",
    "\n",
    "# McDonaldsMenu 클래스 인스턴스 생성 및 실행\n",
    "menu = McDonaldsMenu()\n",
    "all_menu_items_by_category = {}\n",
    "\n",
    "# 각 카테고리별로 메뉴 데이터를 가져와 저장\n",
    "for sub_category_seq in range(1, 16):  # 카테고리 번호 1부터 15까지 반복\n",
    "    all_menu_items = []\n",
    "    for page_num in range(1, 6):  # 각 카테고리에서 5 페이지까지 데이터를 가져옴\n",
    "        menu_data = menu.fetch_menu_data(sub_category_seq, page_num)\n",
    "        if not menu_data:\n",
    "            break  # 더 이상 데이터가 없으면 루프 중단\n",
    "        all_menu_items.extend(menu_data)  # 데이터를 리스트에 추가\n",
    "    all_menu_items_by_category[sub_category_seq] = all_menu_items  # 카테고리별로 데이터를 저장\n",
    "\n",
    "menu.save_menus_to_file(all_menu_items_by_category)  # 모든 메뉴 데이터를 하나의 파일로 저장\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
